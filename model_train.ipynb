{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk, Sequence, Value\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import evaluate\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from typing import Optional, Dict\n",
    "from torch import FloatTensor, tensor\n",
    "import logging\n",
    "from sklearn.metrics import classification_report, hamming_loss\n",
    "from transformers import EvalPrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "Will be training 3 datasets and comparing performances:\n",
    "1. goEmotions + other datasets + textattack data augmentation\n",
    "2. goEmotions + other datasets\n",
    "3. original goEmotions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
    "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
    "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
    "    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]\n",
    "\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load base model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert/distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=len(labels),     \n",
    "    problem_type=\"multi_label_classification\", # uses BCEWithLogitsLoss by default)\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding will be dynamically done in batching with DataCollatorWithPadding\n",
    "def tokenize_func(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets\n",
    "Will be training 3 different datasets\n",
    "- goEmotions (go)\n",
    "- goEmotions + other datasets (merged)\n",
    "- goEmotions + other datasets + textattack data augmentation (augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented\n",
    "dataset = load_from_disk('./datasets/cleaned_hf/augmented_hf')\n",
    "# # merged\n",
    "# dataset = load_from_disk('./datasets/cleaned_hf/merged_hf')\n",
    "# # go\n",
    "# dataset = load_from_disk('./datasets/cleaned_hf/goEmotions_cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset['train']['labels'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to use BCEWithLogitsLoss, we need to convert labels to float or it'll give errors\n",
    "# https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\n",
    "# https://discuss.pytorch.org/t/multi-label-binary-classification-result-type-float-cant-be-cast-to-the-desired-output-type-long/117915/3\n",
    "dataset = dataset.cast_column('labels', Sequence(feature=Value(dtype='float32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset['train']['labels'][1][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm sorry to hear, come see me when you die.\",\n",
       " 'i feel terrified because even if i have the time to write out how i feel about mr',\n",
       " 'I asked at the Bodies Reveled show if they used prisoner bodies.. I got an awkward no.',\n",
       " 'i feel awful for making this all about me and my flawed academia instilled value system but my brain won t shut up about it',\n",
       " 'i feel so repressed when compared to dear a href http eurodancemix']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before shuffle\n",
    "dataset['train']['text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle training set\n",
    "dataset['train'] = dataset['train'].shuffle(seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I gave up trying to be 'normal' years ago. But I get your point though.\",\n",
       " '@blue_north27 http://twitpic.com/4jcjr - Mmm yummy... looks like an invitation to me',\n",
       " 'I feel a connection to this woman',\n",
       " 'My friends are awesome! @JNBlack @koreantomcruise -- and the non Twitter ones here right now too!!',\n",
       " 'People like you is also why no players want to play and stay in Orlando']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after shuffle\n",
    "dataset['train']['text'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_class_weights import generate_class_weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7691456243514355,\n",
       " 1: 1.3645066273932254,\n",
       " 2: 0.49946091644204854,\n",
       " 3: 1.2860613071139386,\n",
       " 4: 1.0808341029504691,\n",
       " 5: 1.779591836734694,\n",
       " 6: 1.401840877569033,\n",
       " 7: 1.4498272152311404,\n",
       " 8: 2.988308023115173,\n",
       " 9: 1.549547038327526,\n",
       " 10: 1.5710046629927936,\n",
       " 11: 0.9356616873553545,\n",
       " 12: 6.0391091797935905,\n",
       " 13: 2.286948472693613,\n",
       " 14: 0.8414758751182593,\n",
       " 15: 1.1933025652033917,\n",
       " 16: 25.210884353741495,\n",
       " 17: 0.3419344917730278,\n",
       " 18: 0.4463357353620105,\n",
       " 19: 12.078218359587181,\n",
       " 20: 0.8910438789821679,\n",
       " 21: 19.488168273444348,\n",
       " 22: 1.7916364515349288,\n",
       " 23: 1.1817602040816326,\n",
       " 24: 3.397402597402597,\n",
       " 25: 0.26198527245949926,\n",
       " 26: 0.8437108708025043,\n",
       " 27: 0.15054127427948574}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = generate_class_weights(dataset['train']['labels'], multi_class=False, one_hot_encoded=True)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadce89540894ada8c885753f2812e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/88944 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3602783adf4488796cb9d0a4d001d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bdb0c784a744d9a8670558924120b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12721 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 88944\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10426\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 12721\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize in batch\n",
    "tokenized_dataset = dataset.map(tokenize_func, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching and Dynamic padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- Will be using `Trainer` instead of `SFTTrainer` because `SFTTrainer` is often for llms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    './models/',\n",
    "    eval_strategy=\"epoch\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "# https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(\n",
    "        y_true=labels,\n",
    "        y_pred=y_pred,\n",
    "        output_dict=True,  # Convert report to a dictionary\n",
    "        zero_division=0  # Avoid division errors for missing labels\n",
    "    )\n",
    "\n",
    "    # Extract key metrics\n",
    "    micro_precision = report[\"micro avg\"][\"precision\"]\n",
    "    micro_recall = report[\"micro avg\"][\"recall\"]\n",
    "    micro_f1 = report[\"micro avg\"][\"f1-score\"]\n",
    "\n",
    "    macro_precision = report[\"macro avg\"][\"precision\"]\n",
    "    macro_recall = report[\"macro avg\"][\"recall\"]\n",
    "    macro_f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "    weighted_precision = report[\"weighted avg\"][\"precision\"]\n",
    "    weighted_recall = report[\"weighted avg\"][\"recall\"]\n",
    "    weighted_f1 = report[\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "\n",
    "    # Combine all metrics into a dictionary\n",
    "    metrics = {\n",
    "        \"micro_precision\": micro_precision,\n",
    "        \"micro_recall\": micro_recall,\n",
    "        \"micro_f1\": micro_f1,\n",
    "        \"macro_precision\": macro_precision,\n",
    "        \"macro_recall\": macro_recall,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"weighted_precision\": weighted_precision,\n",
    "        \"weighted_recall\": weighted_recall,\n",
    "        \"weighted_f1\": weighted_f1,\n",
    "        \"hamming_loss\": hamming\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Class Weighting Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://discuss.huggingface.co/t/mullti-label-text-classification/44233/3\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights: Optional[Dict[int, float]] = None, processing_class: Optional[AutoTokenizer] = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if class_weights is not None:\n",
    "            # dict --> FloatTensor\n",
    "            if isinstance(class_weights, dict):\n",
    "                # Convert to list of values and then to FloatTensor\n",
    "                class_weights = tensor(list(class_weights.values()), dtype=torch.float)\n",
    "                logging.info(f\"Converted class_weights to FloatTensor: {class_weights}\")\n",
    "            elif not isinstance(class_weights, FloatTensor):\n",
    "                raise ValueError(\"class_weights must be a dict or a FloatTensor\")\n",
    "            class_weights = class_weights.to(self.args.device)\n",
    "\n",
    "        self.loss_fct = BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "\n",
    "        # If processing_class is passed, use it\n",
    "        if processing_class is not None:\n",
    "            self.processing_class = processing_class  # Handling tokenizer using processing_class argument\n",
    "        else:\n",
    "            self.processing_class = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \"\"\"\n",
    "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "        Subclass and override for custom behavior.\n",
    "        \"\"\"\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        try:\n",
    "            loss = self.loss_fct(outputs.logits.view(-1, model.num_labels), labels.view(-1, model.num_labels))\n",
    "        except AttributeError:  # DataParallel\n",
    "            loss = self.loss_fct(outputs.logits.view(-1, model.module.num_labels), labels.view(-1, model.num_labels))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = tokenized_dataset[\"train\"].select(range(100))\n",
    "eval_subset = tokenized_dataset[\"validation\"].select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WeightedTrainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mWeightedTrainer\u001b[49m(\n\u001b[0;32m      2\u001b[0m     model,\n\u001b[0;32m      3\u001b[0m     training_args,\n\u001b[0;32m      4\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_subset,\n\u001b[0;32m      5\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39meval_subset,\n\u001b[0;32m      6\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[0;32m      7\u001b[0m     processing_class\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m      8\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'WeightedTrainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = WeightedTrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=eval_subset,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229c65b995214a6e98da2d13b1b08975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.17317159473896027,\n",
       " 'eval_micro_precision': 1.0,\n",
       " 'eval_micro_recall': 0.008064516129032258,\n",
       " 'eval_micro_f1': 0.016,\n",
       " 'eval_macro_precision': 0.03571428571428571,\n",
       " 'eval_macro_recall': 0.0011160714285714285,\n",
       " 'eval_macro_f1': 0.0021645021645021645,\n",
       " 'eval_weighted_precision': 0.25806451612903225,\n",
       " 'eval_weighted_recall': 0.008064516129032258,\n",
       " 'eval_weighted_f1': 0.015640273704789834,\n",
       " 'eval_hamming_loss': 0.04392857142857143,\n",
       " 'eval_runtime': 0.2613,\n",
       " 'eval_samples_per_second': 382.699,\n",
       " 'eval_steps_per_second': 49.751,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(tokenized_dataset['test'][:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
